import os
import json
import logging
import time
from pathlib import Path
from typing import List, Dict, Optional

from bs4 import BeautifulSoup
from selenium import webdriver
from selenium.webdriver.chrome.service import Service
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC

# -------------------- Logging --------------------
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s - %(levelname)s - %(message)s",
    datefmt="%Y-%m-%d %H:%M:%S",
)
logger = logging.getLogger(__name__)


# -------------------- Parser --------------------
class AruodasParser:
    BASE_URL = "https://ru.aruodas.lt"

    def __init__(self, config_path: str = "config.json", headless: bool = True):
        self.config = self._load_config(config_path)
        self.driver = self._init_driver(headless)

    # ---------- Config ----------
    def _load_config(self, path: str) -> dict:
        file = Path(path)
        if not file.exists():
            logger.warning(f"–ö–æ–Ω—Ñ–∏–≥ {path} –Ω–µ –Ω–∞–π–¥–µ–Ω. –°–æ–∑–¥–∞—ë–º –¥–µ—Ñ–æ–ª—Ç–Ω—ã–π.")
            default = {
                "search_params": {
                    "FRadius": 5,
                    "FAreaOverAllMin": 60,
                    "FPriceMax": 1200,
                    "detailed_search": 1,
                    "pet_friendly": 1,
                },
                "city": "vilniuje",
                "type": "butu-nuoma",
                "max_pages": 3,
            }
            self._save_config(path, default)
            return default
        return json.loads(file.read_text(encoding="utf-8"))

    def _save_config(self, path: str, config: dict):
        Path(path).write_text(
            json.dumps(config, ensure_ascii=False, indent=2), encoding="utf-8"
        )

    # ---------- Driver ----------
    def _init_driver(self, headless: bool) -> webdriver.Chrome:
        options = Options()
        if headless:
            options.add_argument("--headless=new")

        options.binary_location = "/snap/bin/chromium"

        # –ë–∞–∑–æ–≤–∞—è –∑–∞—â–∏—Ç–∞ –æ—Ç –¥–µ—Ç–µ–∫—Ü–∏–∏
        options.add_argument("--disable-blink-features=AutomationControlled")
        options.add_argument("--no-sandbox")
        options.add_argument("--disable-dev-shm-usage")
        options.add_argument("--disable-gpu")
        options.add_argument("--disable-extensions")
        options.add_argument("--disable-software-rasterizer")
        options.add_argument("--no-first-run")
        options.add_argument("--no-zygote")

        # –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è —Ñ–æ–Ω–æ–≤—ã—Ö –ø—Ä–æ—Ü–µ—Å—Å–æ–≤
        options.add_argument("--disable-background-networking")
        options.add_argument("--disable-sync")
        options.add_argument("--disable-translate")
        options.add_argument("--disable-features=TranslateUI")
        options.add_argument("--disable-renderer-backgrounding")
        options.add_argument("--disable-backgrounding-occluded-windows")
        options.add_argument("--disable-client-side-phishing-detection")
        options.add_argument("--disable-default-apps")
        options.add_argument("--disable-hang-monitor")
        options.add_argument("--disable-popup-blocking")
        options.add_argument("--disable-prompt-on-repost")
        options.add_argument("--metrics-recording-only")
        options.add_argument("--mute-audio")
        options.add_argument("--no-default-browser-check")
        options.add_argument("--safebrowsing-disable-auto-update")
        options.add_argument("--password-store=basic")
        options.add_argument("--use-mock-keychain")
        options.add_argument("--force-color-profile=srgb")

        # üî• –í–ê–ñ–ù–û: —É–±—Ä–∞–ª–∏ single-process –∏ remote-debugging-port
        # options.add_argument("--single-process")  ‚ùå
        # options.add_argument("--remote-debugging-port=9222") ‚ùå

        # –ú–∏–Ω–∏–º–∞–ª—å–Ω—ã–π –∫—ç—à
        options.add_argument("--disk-cache-size=1")
        options.add_argument("--media-cache-size=1")
        options.add_argument("--js-flags=--max-old-space-size=128")

        # üî• –û—Ç–∫–ª—é—á–∞–µ–º –∫–∞—Ä—Ç–∏–Ω–∫–∏ –∏ —à—Ä–∏—Ñ—Ç—ã ‚Äî —Å–∏–ª—å–Ω–∞—è —ç–∫–æ–Ω–æ–º–∏—è –ø–∞–º—è—Ç–∏
        prefs = {
            "profile.managed_default_content_settings.images": 2,
            "profile.managed_default_content_settings.fonts": 2,
        }
        options.add_experimental_option("prefs", prefs)

        options.add_experimental_option("excludeSwitches", ["enable-automation"])
        options.add_experimental_option("useAutomationExtension", False)

        service = Service("/usr/local/bin/chromedriver")
        driver = webdriver.Chrome(service=service, options=options)

        driver.execute_script(
            "Object.defineProperty(navigator, 'webdriver', {get: () => undefined})"
        )

        return driver

    # ---------- URL ----------
    def build_search_url(self, page: int = 1) -> str:
        params = "&".join(f"{k}={v}" for k, v in self.config["search_params"].items())
        url = f"{self.BASE_URL}/{self.config['type']}/{self.config['city']}/?{params}"
        if page > 1:
            url += f"&page={page}"
        return url

    # ---------- Parsing ----------
    def parse_all_pages(self) -> Optional[List[Dict]]:
        all_apartments = []
        seen_ids = set()
        max_pages = self.config.get("max_pages", 3)

        for page in range(1, max_pages + 1):
            url = self.build_search_url(page)
            apartments = self._parse_page(url)

            if apartments is None:
                logger.error(f"–ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ –Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü–µ {page}")
                return None

            if not apartments:
                break

            # –î–µ–¥—É–ø–ª–∏–∫–∞—Ü–∏—è: –¥–æ–±–∞–≤–ª—è–µ–º —Ç–æ–ª—å–∫–æ —É–Ω–∏–∫–∞–ª—å–Ω—ã–µ –æ–±—ä—è–≤–ª–µ–Ω–∏—è
            for apt in apartments:
                if apt["id"] not in seen_ids:
                    all_apartments.append(apt)
                    seen_ids.add(apt["id"])

            if page < max_pages:
                time.sleep(2)

        logger.info(f"–ù–∞–π–¥–µ–Ω–æ {len(all_apartments)} —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –∫–≤–∞—Ä—Ç–∏—Ä")
        return all_apartments

    def _parse_page(self, url: str) -> Optional[List[Dict]]:
        try:
            self.driver.get(url)

            # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ 403/–±–ª–æ–∫–∏—Ä–æ–≤–∫—É
            if "403" in self.driver.title or "Access Denied" in self.driver.page_source:
                logger.error("–ü–æ–ª—É—á–µ–Ω 403 –∏–ª–∏ –±–ª–æ–∫–∏—Ä–æ–≤–∫–∞")
                return None

            time.sleep(3)
            try:
                WebDriverWait(self.driver, 15).until(
                    EC.presence_of_element_located((By.CLASS_NAME, "list-row-v2"))
                )
            except Exception:
                pass

            soup = BeautifulSoup(self.driver.page_source, "html.parser")
            listings = soup.find_all("div", class_="list-row-v2")

            if not listings:
                return []

            return [
                self._parse_apartment(l) for l in listings if self._parse_apartment(l)
            ]
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–∞—Ä—Å–∏–Ω–≥–µ —Å—Ç—Ä–∞–Ω–∏—Ü—ã: {e}", exc_info=True)
            return None

    def _parse_apartment(self, listing) -> Optional[Dict]:
        try:
            save_btn = listing.find("div", class_="advert-controls-save-v2")
            if not save_btn or not save_btn.get("data-id"):
                return None

            def text(cls, tag="div"):  # –≤—Å–ø–æ–º–æ–≥–∞—Ç–µ–ª—å–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è
                el = listing.find(tag, class_=cls)
                return el.get_text(strip=True) if el else None

            apartment = {
                "id": save_btn["data-id"],
                "url": (listing.find("a", href=True) or {})
                .get("href", "")
                .split("?")[0],
                "address": (
                    ", ".join(
                        s.strip()
                        for s in (
                            listing.find(
                                "div", class_="list-adress-v2"
                            ).h3.stripped_strings
                        )
                        if "–∫–º –¥–æ —Ç–æ—á–∫–∏" not in s
                    )
                    if listing.find("div", class_="list-adress-v2")
                    else None
                ),
                "distance": text("accent", "span"),
                "price": text("list-item-price-v2", "span"),
                "price_per_m2": text("price-pm-v2", "span"),
                "rooms": text("list-RoomNum-v2"),
                "area": text("list-AreaOverall-v2"),
                "floor": text("list-Floors-v2"),
                "pet_friendly": bool(listing.find("div", class_="pet_friendly_info")),
                "price_change": text("price-change"),
            }
            return apartment
        except Exception as e:
            logger.warning(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–∞—Ä—Å–∏–Ω–≥–µ –æ–±—ä—è–≤–ª–µ–Ω–∏—è: {e}")
            return None

    # ---------- Close ----------
    def close(self):
        if self.driver:
            try:
                self.driver.quit()
            except Exception as e:
                logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–∫—Ä—ã—Ç–∏–∏ –¥—Ä–∞–π–≤–µ—Ä–∞: {e}")
            finally:
                self.driver = None  # üî• –∫—Ä–∏—Ç–∏—á–Ω–æ –¥–ª—è GC

# -------------------- Launcher for bot --------------------
def fetch_new_apartments(
    config_path: str = "config.json",
    published_ids_path: str = "published_ids.json",
    headless: bool = False,
) -> Optional[List[Dict]]:
    """
    –ü–∞—Ä—Å–∏—Ç –≤—Å–µ –∫–≤–∞—Ä—Ç–∏—Ä—ã –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –∏—Ö –ë–ï–ó –§–ò–õ–¨–¢–†–ê–¶–ò–ò.
    –§–∏–ª—å—Ç—Ä–∞—Ü–∏—é –¥–µ–ª–∞–µ—Ç –±–æ—Ç, —Ç.–∫. —Ñ–∞–π–ª published_ids –º–æ–∂–µ—Ç –∏–∑–º–µ–Ω–∏—Ç—å—Å—è –≤–æ –≤—Ä–µ–º—è –ø–∞—Ä—Å–∏–Ω–≥–∞.
    """
    parser = None
    try:
        parser = AruodasParser(config_path=config_path, headless=headless)
        all_apartments = parser.parse_all_pages()

        if all_apartments is None:
            logger.error("–ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞")
            return None

        return all_apartments

    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞: {e}", exc_info=True)
        return None

    finally:
        if parser is not None:
            parser.close()
            os.system("pkill -f chromium || true")
